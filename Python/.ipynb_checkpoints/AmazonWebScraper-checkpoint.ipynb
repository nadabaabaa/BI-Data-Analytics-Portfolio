{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "653fee67-1694-4b9b-98b9-be9c2239bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.32.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\info genie\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.32.0-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.4 MB 353.3 kB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 1.0/9.4 MB 419.4 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 1.6/9.4 MB 640.3 kB/s eta 0:00:13\n",
      "   ------- -------------------------------- 1.8/9.4 MB 689.5 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.8/9.4 MB 689.5 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.8/9.4 MB 689.5 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.1/9.4 MB 631.5 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.1/9.4 MB 631.5 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.1/9.4 MB 631.5 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 607.3 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 645.3 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 2.9/9.4 MB 684.8 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 3.1/9.4 MB 712.5 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 3.7/9.4 MB 784.5 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 867.8 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.5/9.4 MB 883.0 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.0/9.4 MB 937.9 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 960.2 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 5.8/9.4 MB 1.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.3/9.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.8/9.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.3/9.4 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.9/9.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.3.0 outcome-1.3.0.post0 selenium-4.32.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42f9add0-9b81-493f-8d67-533a7582352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import smtplib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac77a2-75b5-4ff9-b011-ec240a78b52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://www.amazon.com/dp/B07PYXYTV3/ref=sspa_dk_detail_2?pd_rd_i=B07PYXYTV3&pd_rd_w=CDBPq&content-id=amzn1.sym.7446a9d1-25fe-4460-b135-a60336bad2c9&pf_rd_p=7446a9d1-25fe-4460-b135-a60336bad2c9&pf_rd_r=48HQPAGNY1MKB0F1WEAE&pd_rd_wg=5Jtsx&pd_rd_r=ef5f4ec3-6891-4743-a774-5bfc433167cc&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw&th=1&psc=1'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "}\n",
    "\n",
    "response = requests.get(URL, headers=headers)\n",
    "\n",
    "# Check if the response was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Extracting the product title\n",
    "    title_tag = soup.find(\"span\", id=\"productTitle\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"Title not found\"\n",
    "    print(title)\n",
    "    \n",
    "    # Extracting the product price\n",
    "    price_tag = soup.find(\"div\", id=\"corePriceDisplay_desktop_feature_div\")\n",
    "    price = price_tag.get_text(strip=True) if price_tag else \"Price not found\"\n",
    "    print(price)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaa1ce53-e906-44d9-bd1d-9a0df2af87bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find X T Shirt Funny Saying Math Teacher Graphic Sarcastic Gift Novelty Dad Joke\n",
      "14.99$14.99\n"
     ]
    }
   ],
   "source": [
    "# Clean up the data a little bit\n",
    "\n",
    "price = price.strip()[1:]\n",
    "title = title.strip()\n",
    "\n",
    "print(title)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735282f-98ad-4417-9f36-0f033792baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Timestamp for your output to track when data was collected\n",
    "\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe387977-cdb6-4fa2-939d-cb40a5732fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File successfully saved to: C:\\Users\\info genie\\Desktop\\BootCamp\\DataPortfolio\\Python\\AmazonWebScraperDataset.csv\n",
      "ðŸ“‚ Current working directory: C:\\Users\\info genie\\Desktop\n"
     ]
    }
   ],
   "source": [
    "# Create CSV and write headers and data into the file\n",
    "\n",
    "import csv \n",
    "import os\n",
    "\n",
    "# Define the header and data\n",
    "header = ['Title', 'Price', 'Date']\n",
    "data = [title, price, today]\n",
    "\n",
    "# Define the full file path\n",
    "file_path = os.path.join(r\"C:\\Users\\info genie\\Desktop\\BootCamp\\DataPortfolio\\Python\", \"AmazonWebScraperDataset.csv\")\n",
    "\n",
    "# Create the CSV file\n",
    "with open(file_path, 'w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)\n",
    "    print(f\"âœ… File successfully saved to: {file_path}\")\n",
    "\n",
    "# Print the current working directory for verification\n",
    "print(\"ðŸ“‚ Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97da93-9b53-4455-b6df-d6c9f595d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Corrected file path\n",
    "df = pd.read_csv(r\"C:\\Users\\info genie\\Desktop\\BootCamp\\DataPortfolio\\Python\\AmazonWebScraperDataset.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a64384-dcba-4275-8e33-47c2ceac315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price():\n",
    "    # Amazon product URL\n",
    "    URL = 'https://www.amazon.com/dp/B07PYXYTV3/ref=sspa_dk_detail_2?pd_rd_i=B07PYXYTV3&pd_rd_w=CDBPq&content-id=amzn1.sym.7446a9d1-25fe-4460-b135-a60336bad2c9&pf_rd_p=7446a9d1-25fe-4460-b135-a60336bad2c9&pf_rd_r=48HQPAGNY1MKB0F1WEAE&pd_rd_wg=5Jtsx&pd_rd_r=ef5f4ec3-6891-4743-a774-5bfc433167cc&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw&th=1&psc=1'\n",
    "\n",
    "    # Headers to simulate a real browser\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "    }\n",
    "\n",
    "    # Send the GET request\n",
    "    response = requests.get(URL, headers=headers)\n",
    "\n",
    "    # Parse the response\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Extracting the product title\n",
    "        title_tag = soup.find(\"span\", id=\"productTitle\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"Title not found\"\n",
    "        \n",
    "        # Extracting the product price\n",
    "        price_tag = soup.find(\"div\", id=\"corePriceDisplay_desktop_feature_div\")\n",
    "        price = price_tag.get_text(strip=True) if price_tag else \"Price not found\"\n",
    "        \n",
    "        # Clean up the price (remove currency symbol)\n",
    "        price = price.replace(\"$\", \"\").split()[0]\n",
    "        \n",
    "        # Get the current date\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        # Define the CSV file path\n",
    "        file_path = os.path.join(r\"C:\\Users\\info genie\\Desktop\\BootCamp\\DataPortfolio\\Python\", \"AmazonWebScraperDataset.csv\")\n",
    "\n",
    "        # Write data to CSV file\n",
    "        header = ['Title', 'Price', 'Date']\n",
    "        data = [title, price, today]\n",
    "        \n",
    "        # Append data if the file exists, create if not\n",
    "        file_exists = os.path.isfile(file_path)\n",
    "        with open(file_path, 'a', newline='', encoding='UTF8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if not file_exists:\n",
    "                writer.writerow(header)  # Write headers only once\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc408b-d6c0-4b73-8914-218011b51272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c4baf-ef00-4a8f-bcec-5992978c75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\info genie\\Desktop\\BootCamp\\DataPortfolio\\Python\\AmazonWebScraperDataset.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832a8a2-82a4-4d26-9299-9ce345bb6dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
